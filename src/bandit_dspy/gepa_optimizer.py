"""
GEPA (Reflective Prompt Evolution) optimizer for security-aware DSPy programs.

This module implements a GEPA optimizer following DSPy patterns that uses LLM 
reflection to iteratively improve the security of generated code through natural 
language feedback and multi-objective optimization.

Based on the GEPA paper: "Reflective Prompt Evolution Can Outperform Reinforcement Learning"
Adapted for security-focused optimization in the DSPy framework.
"""

import dspy
import random
import json
import hashlib
from typing import List, Dict, Any, Optional, Tuple, Set, Union
from dataclasses import dataclass, field
from collections import defaultdict
from dspy.teleprompt import Teleprompter


@dataclass
class SecurityReflection:
    """Stores security-focused reflection data."""
    code: str
    security_issues: List[Dict[str, Any]]
    security_score: float
    performance_score: float
    reflection_text: str
    proposed_improvements: List[str]
    trajectory_summary: str


@dataclass
class GEPACandidate:
    """Represents a candidate program configuration for GEPA optimization."""
    instruction_prompt: str
    few_shot_examples: List[Any]
    security_guidelines: str
    performance_config: Dict[str, Any]
    candidate_id: str
    scores: Dict[str, float] = None
    
    def __hash__(self):
        return hash(self.candidate_id)


class SecurityReflector(dspy.Module):
    """Uses LLM reflection to analyze security issues and propose improvements."""
    
    def __init__(self, reflection_lm: Optional[dspy.LM] = None):
        super().__init__()
        self.reflection_lm = reflection_lm or dspy.settings.lm
        self.reflector = dspy.Predict(self._get_reflection_signature())
    
    def _get_reflection_signature(self):
        """Define the signature for security reflection."""
        class SecurityReflectionSignature(dspy.Signature):
            """Analyze code generation trajectory and security issues to propose improvements.
            
            You are a security expert analyzing LLM-generated code. Your task is to:
            1. Identify security vulnerabilities and their root causes
            2. Analyze why the current prompt/configuration led to insecure code
            3. Propose specific improvements to prompts and examples
            4. Consider trade-offs between security and functionality
            """
            
            # Inputs
            generated_code = dspy.InputField(desc="The Python code generated by the LLM")
            security_issues = dspy.InputField(desc="List of security issues found by static analysis")
            current_instruction = dspy.InputField(desc="Current instruction prompt used")
            few_shot_examples = dspy.InputField(desc="Current few-shot examples used")
            security_guidelines = dspy.InputField(desc="Current security guidelines")
            execution_trace = dspy.InputField(desc="Details of how the code was generated")
            
            # Outputs
            problem_diagnosis = dspy.OutputField(desc="Analysis of why security issues occurred")
            root_cause_analysis = dspy.OutputField(desc="Deeper analysis of prompt/example weaknesses")
            improved_instruction = dspy.OutputField(desc="Improved instruction prompt focusing on security")
            improved_guidelines = dspy.OutputField(desc="Enhanced security guidelines")
            example_improvements = dspy.OutputField(desc="Suggestions for better few-shot examples")
            security_trade_offs = dspy.OutputField(desc="Analysis of security vs functionality trade-offs")
            
        return SecurityReflectionSignature
    
    def forward(self, trajectory_data: Dict[str, Any]) -> SecurityReflection:
        """Perform security-focused reflection on generation trajectory."""
        
        # Prepare inputs for reflection
        security_issues_text = self._format_security_issues(trajectory_data.get('security_issues', []))
        examples_text = self._format_examples(trajectory_data.get('few_shot_examples', []))
        
        # Use stronger LM for reflection if available
        with dspy.context(lm=self.reflection_lm):
            reflection_result = self.reflector(
                generated_code=trajectory_data.get('code', ''),
                security_issues=security_issues_text,
                current_instruction=trajectory_data.get('instruction', ''),
                few_shot_examples=examples_text,
                security_guidelines=trajectory_data.get('security_guidelines', ''),
                execution_trace=trajectory_data.get('trace', '')
            )
        
        # Extract improvement suggestions
        improvements = self._extract_improvements(reflection_result)
        
        return SecurityReflection(
            code=trajectory_data.get('code', ''),
            security_issues=trajectory_data.get('security_issues', []),
            security_score=trajectory_data.get('security_score', 0.0),
            performance_score=trajectory_data.get('performance_score', 0.0),
            reflection_text=reflection_result.problem_diagnosis,
            proposed_improvements=improvements,
            trajectory_summary=reflection_result.root_cause_analysis
        )
    
    def _format_security_issues(self, issues: List[Dict[str, Any]]) -> str:
        """Format security issues for reflection input."""
        if not issues:
            return "No security issues detected."
        
        formatted = []
        for issue in issues:
            formatted.append(f"- {issue.get('test_id', 'Unknown')}: {issue.get('description', 'No description')}")
        return "\n".join(formatted)
    
    def _format_examples(self, examples: List[Any]) -> str:
        """Format few-shot examples for reflection input."""
        if not examples:
            return "No few-shot examples provided."
        
        formatted = []
        for i, example in enumerate(examples[:3]):  # Limit to first 3 for brevity
            if hasattr(example, 'description') and hasattr(example, 'code'):
                formatted.append(f"Example {i+1}: {example.description} -> {example.code[:100]}...")
        return "\n".join(formatted)
    
    def _extract_improvements(self, reflection_result) -> List[str]:
        """Extract actionable improvements from reflection."""
        improvements = []
        
        # Extract from different fields
        if hasattr(reflection_result, 'improved_instruction'):
            improvements.append(f"Instruction: {reflection_result.improved_instruction}")
        if hasattr(reflection_result, 'improved_guidelines'):
            improvements.append(f"Guidelines: {reflection_result.improved_guidelines}")
        if hasattr(reflection_result, 'example_improvements'):
            improvements.append(f"Examples: {reflection_result.example_improvements}")
        
        return improvements


class ParetoSelector:
    """Implements Pareto-based candidate selection for multi-objective optimization."""
    
    def __init__(self, objectives: List[str] = None):
        self.objectives = objectives or ['security_score', 'performance_score', 'functionality_score']
        self.pareto_front = []
        self.dominated_solutions = []
    
    def add_candidate(self, candidate: GEPACandidate) -> bool:
        """Add candidate to Pareto front if non-dominated."""
        if candidate.scores is None:
            return False
        
        # Check if candidate is dominated by existing solutions
        is_dominated = False
        dominated_existing = []
        
        for existing in self.pareto_front[:]:
            dominance = self._compare_candidates(candidate, existing)
            
            if dominance == -1:  # candidate is dominated
                is_dominated = True
                break
            elif dominance == 1:  # candidate dominates existing
                dominated_existing.append(existing)
        
        if not is_dominated:
            # Remove dominated solutions
            for dominated in dominated_existing:
                self.pareto_front.remove(dominated)
                self.dominated_solutions.append(dominated)
            
            # Add new candidate to front
            self.pareto_front.append(candidate)
            return True
        
        return False
    
    def _compare_candidates(self, a: GEPACandidate, b: GEPACandidate) -> int:
        """Compare two candidates. Returns 1 if a dominates b, -1 if b dominates a, 0 if neither."""
        a_better = 0
        b_better = 0
        
        for objective in self.objectives:
            a_score = a.scores.get(objective, 0)
            b_score = b.scores.get(objective, 0)
            
            if a_score > b_score:
                a_better += 1
            elif b_score > a_score:
                b_better += 1
        
        if a_better > 0 and b_better == 0:
            return 1  # a dominates b
        elif b_better > 0 and a_better == 0:
            return -1  # b dominates a
        else:
            return 0  # neither dominates
    
    def get_best_candidates(self, k: int = 5) -> List[GEPACandidate]:
        """Get k best candidates from Pareto front."""
        if len(self.pareto_front) <= k:
            return self.pareto_front[:]
        
        # Score candidates by distance from ideal point
        ideal_point = {obj: max(c.scores.get(obj, 0) for c in self.pareto_front) 
                      for obj in self.objectives}
        
        scored_candidates = []
        for candidate in self.pareto_front:
            distance = sum((ideal_point[obj] - candidate.scores.get(obj, 0))**2 
                          for obj in self.objectives)**0.5
            scored_candidates.append((distance, candidate))
        
        # Return k candidates closest to ideal point
        scored_candidates.sort(key=lambda x: x[0])
        return [candidate for _, candidate in scored_candidates[:k]]


class SecurityGEPAOptimizer:
    """GEPA optimizer specialized for security-aware code generation."""
    
    def __init__(self, 
                 task_lm: Optional[dspy.LM] = None,
                 reflection_lm: Optional[dspy.LM] = None,
                 max_iterations: int = 10,
                 population_size: int = 8,
                 reflection_frequency: int = 3):
        """
        Initialize GEPA optimizer for security.
        
        Args:
            task_lm: LM for code generation (being optimized)
            reflection_lm: Stronger LM for reflection (should be more capable)
            max_iterations: Maximum optimization iterations
            population_size: Number of candidates to maintain
            reflection_frequency: How often to perform reflection
        """
        self.task_lm = task_lm or dspy.settings.lm
        self.reflection_lm = reflection_lm or dspy.settings.lm
        self.max_iterations = max_iterations
        self.population_size = population_size
        self.reflection_frequency = reflection_frequency
        
        self.reflector = SecurityReflector(reflection_lm)
        self.pareto_selector = ParetoSelector()
        self.reflection_history = []
        self.best_candidates = []
        
    def optimize(self, 
                 student_program: dspy.Module,
                 trainset: List[Any],
                 security_metric,
                 seed_instruction: str = None,
                 seed_examples: List[Any] = None) -> Tuple[dspy.Module, Dict[str, Any]]:
        """
        Run GEPA optimization for security-aware code generation.
        
        Args:
            student_program: DSPy module to optimize
            trainset: Training examples
            security_metric: Security evaluation function
            seed_instruction: Initial instruction prompt
            seed_examples: Initial few-shot examples
            
        Returns:
            Optimized program and optimization history
        """
        
        # Initialize population with seed candidate
        population = self._initialize_population(
            seed_instruction, seed_examples, trainset
        )
        
        optimization_history = {
            'iterations': [],
            'reflections': [],
            'pareto_front_evolution': [],
            'best_scores': []
        }
        
        for iteration in range(self.max_iterations):
            print(f"GEPA Iteration {iteration + 1}/{self.max_iterations}")
            
            # Evaluate all candidates
            iteration_results = []
            for candidate in population:
                scores, trajectory = self._evaluate_candidate(
                    candidate, student_program, trainset, security_metric
                )
                candidate.scores = scores
                iteration_results.append((candidate, trajectory))
                
                # Add to Pareto front
                self.pareto_selector.add_candidate(candidate)
            
            # Perform reflection every N iterations
            if (iteration + 1) % self.reflection_frequency == 0:
                reflections = self._perform_reflection(iteration_results)
                self.reflection_history.extend(reflections)
                optimization_history['reflections'].append(reflections)
                
                # Generate new candidates based on reflections
                new_candidates = self._generate_candidates_from_reflection(
                    reflections, trainset
                )
                population.extend(new_candidates)
            
            # Select best candidates for next iteration
            population = self.pareto_selector.get_best_candidates(self.population_size)
            
            # Track progress
            best_candidate = max(population, key=lambda c: c.scores.get('security_score', 0))
            optimization_history['iterations'].append({
                'iteration': iteration,
                'best_security_score': best_candidate.scores.get('security_score', 0),
                'population_size': len(population),
                'pareto_front_size': len(self.pareto_selector.pareto_front)
            })
            
            print(f"  Best Security Score: {best_candidate.scores.get('security_score', 0):.3f}")
            print(f"  Pareto Front Size: {len(self.pareto_selector.pareto_front)}")
        
        # Select final best candidate
        final_candidates = self.pareto_selector.get_best_candidates(1)
        best_candidate = final_candidates[0] if final_candidates else population[0]
        
        # Create optimized program
        optimized_program = self._create_optimized_program(
            student_program, best_candidate
        )
        
        return optimized_program, optimization_history
    
    def _initialize_population(self, 
                             seed_instruction: str, 
                             seed_examples: List[Any], 
                             trainset: List[Any]) -> List[GEPACandidate]:
        """Initialize candidate population."""
        population = []
        
        # Seed candidate
        seed_candidate = GEPACandidate(
            instruction_prompt=seed_instruction or "Generate secure Python code for the given task.",
            few_shot_examples=seed_examples or random.sample(trainset, min(3, len(trainset))),
            security_guidelines="Follow secure coding practices. Avoid hardcoded secrets, SQL injection, and unsafe operations.",
            performance_config={'max_tokens': 500, 'temperature': 0.3},
            candidate_id=f"seed_0"
        )
        population.append(seed_candidate)
        
        # Generate initial variations
        for i in range(self.population_size - 1):
            variant = self._mutate_candidate(seed_candidate, i + 1, trainset)
            population.append(variant)
        
        return population
    
    def _evaluate_candidate(self, 
                          candidate: GEPACandidate, 
                          student_program: dspy.Module,
                          trainset: List[Any],
                          security_metric) -> Tuple[Dict[str, float], Dict[str, Any]]:
        """Evaluate a candidate configuration."""
        
        # Configure program with candidate settings
        configured_program = self._configure_program(student_program, candidate)
        
        # Evaluate on sample of trainset
        sample_size = min(5, len(trainset))
        sample_examples = random.sample(trainset, sample_size)
        
        security_scores = []
        trajectories = []
        
        for example in sample_examples:
            # Generate code
            with dspy.context(lm=self.task_lm):
                prediction = configured_program(**example.inputs())
            
            # Evaluate security
            security_result = security_metric(example, prediction)
            security_scores.append(security_result['score'])
            
            # Store trajectory information
            trajectory = {
                'input': example.inputs(),
                'code': prediction.code if hasattr(prediction, 'code') else str(prediction),
                'security_issues': security_result.get('issues', []),
                'instruction': candidate.instruction_prompt,
                'few_shot_examples': candidate.few_shot_examples,
                'security_guidelines': candidate.security_guidelines
            }
            trajectories.append(trajectory)
        
        # Calculate aggregate scores
        avg_security_score = sum(security_scores) / len(security_scores) if security_scores else 0
        
        # TODO: Add performance and functionality scoring
        performance_score = 1.0 - (len(str(trajectories[0]['code'])) / 1000)  # Simple proxy
        functionality_score = 0.8  # Placeholder
        
        scores = {
            'security_score': avg_security_score,
            'performance_score': max(0, min(1, performance_score)),
            'functionality_score': functionality_score
        }
        
        trajectory_summary = {
            'candidate_id': candidate.candidate_id,
            'scores': scores,
            'trajectories': trajectories,
            'instruction': candidate.instruction_prompt,
            'security_guidelines': candidate.security_guidelines
        }
        
        return scores, trajectory_summary
    
    def _perform_reflection(self, iteration_results: List[Tuple[GEPACandidate, Dict]]) -> List[SecurityReflection]:
        """Perform LLM-based reflection on iteration results."""
        reflections = []
        
        # Focus on worst-performing candidates for reflection
        sorted_results = sorted(iteration_results, 
                              key=lambda x: x[0].scores.get('security_score', 0))
        
        # Reflect on worst 2-3 candidates
        for candidate, trajectory in sorted_results[:3]:
            if trajectory['trajectories']:
                # Use first trajectory as representative
                sample_trajectory = trajectory['trajectories'][0]
                
                reflection_data = {
                    'code': sample_trajectory['code'],
                    'security_issues': sample_trajectory['security_issues'],
                    'security_score': candidate.scores.get('security_score', 0),
                    'performance_score': candidate.scores.get('performance_score', 0),
                    'instruction': candidate.instruction_prompt,
                    'few_shot_examples': candidate.few_shot_examples,
                    'security_guidelines': candidate.security_guidelines,
                    'trace': f"Generated with instruction: {candidate.instruction_prompt}"
                }
                
                reflection = self.reflector(reflection_data)
                reflections.append(reflection)
        
        return reflections
    
    def _generate_candidates_from_reflection(self, 
                                           reflections: List[SecurityReflection],
                                           trainset: List[Any]) -> List[GEPACandidate]:
        """Generate new candidates based on reflection insights."""
        new_candidates = []
        
        for i, reflection in enumerate(reflections):
            # Extract improvements from reflection
            improved_instruction = self._extract_improved_instruction(reflection)
            improved_guidelines = self._extract_improved_guidelines(reflection)
            
            # Create new candidate
            new_candidate = GEPACandidate(
                instruction_prompt=improved_instruction,
                few_shot_examples=random.sample(trainset, min(3, len(trainset))),
                security_guidelines=improved_guidelines,
                performance_config={'max_tokens': 500, 'temperature': 0.2},
                candidate_id=f"reflection_{i}_{random.randint(1000, 9999)}"
            )
            new_candidates.append(new_candidate)
        
        return new_candidates
    
    def _extract_improved_instruction(self, reflection: SecurityReflection) -> str:
        """Extract improved instruction from reflection."""
        # Look for instruction improvements in the reflection text
        for improvement in reflection.proposed_improvements:
            if 'Instruction:' in improvement:
                return improvement.replace('Instruction:', '').strip()
        
        # Fallback: enhance original with security focus
        return ("Generate secure Python code for the given task. "
                "Prioritize security over convenience. Avoid hardcoded credentials, "
                "validate inputs, and use secure APIs.")
    
    def _extract_improved_guidelines(self, reflection: SecurityReflection) -> str:
        """Extract improved security guidelines from reflection."""
        for improvement in reflection.proposed_improvements:
            if 'Guidelines:' in improvement:
                return improvement.replace('Guidelines:', '').strip()
        
        # Fallback: comprehensive security guidelines
        return ("1. Never hardcode passwords or API keys\n"
                "2. Validate and sanitize all inputs\n"
                "3. Use parameterized queries for database access\n"
                "4. Handle errors gracefully without exposing internals\n"
                "5. Use secure random number generation")
    
    def _mutate_candidate(self, 
                         base_candidate: GEPACandidate, 
                         mutation_id: int,
                         trainset: List[Any]) -> GEPACandidate:
        """Create mutated version of candidate."""
        mutation_types = ['instruction', 'examples', 'guidelines', 'config']
        mutation_type = random.choice(mutation_types)
        
        new_candidate = GEPACandidate(
            instruction_prompt=base_candidate.instruction_prompt,
            few_shot_examples=base_candidate.few_shot_examples[:],
            security_guidelines=base_candidate.security_guidelines,
            performance_config=base_candidate.performance_config.copy(),
            candidate_id=f"mutation_{mutation_id}_{mutation_type}"
        )
        
        if mutation_type == 'instruction':
            variations = [
                "Write secure Python code that",
                "Generate Python code following security best practices for",
                "Create secure and robust Python code to",
                "Develop security-conscious Python code that"
            ]
            new_candidate.instruction_prompt = random.choice(variations) + " the given task."
        
        elif mutation_type == 'examples':
            # Randomly sample different examples
            new_candidate.few_shot_examples = random.sample(
                trainset, min(random.randint(1, 5), len(trainset))
            )
        
        elif mutation_type == 'guidelines':
            guidelines_variants = [
                "Focus on input validation and secure coding practices.",
                "Prioritize security over performance. Validate all inputs.",
                "Use secure APIs and avoid common vulnerabilities like SQL injection.",
                "Follow OWASP guidelines and secure coding standards."
            ]
            new_candidate.security_guidelines = random.choice(guidelines_variants)
        
        elif mutation_type == 'config':
            new_candidate.performance_config['temperature'] = random.uniform(0.1, 0.5)
            new_candidate.performance_config['max_tokens'] = random.choice([300, 400, 500, 600])
        
        return new_candidate
    
    def _configure_program(self, 
                          student_program: dspy.Module, 
                          candidate: GEPACandidate) -> dspy.Module:
        """Configure student program with candidate settings."""
        configured_program = student_program.deepcopy() if hasattr(student_program, 'deepcopy') else student_program
        
        # Configure prediction modules with enhanced prompts
        for name, module in configured_program.named_modules():
            if isinstance(module, dspy.Predict):
                # Enhance signature with security guidelines
                original_signature = module.signature
                
                # Create enhanced signature class
                class SecurityEnhancedSignature(original_signature):
                    pass
                
                # Modify the docstring to include security guidelines
                if hasattr(original_signature, '__doc__') and original_signature.__doc__:
                    enhanced_doc = f"{original_signature.__doc__}\n\nSECURITY GUIDELINES:\n{candidate.security_guidelines}\n\nINSTRUCTION: {candidate.instruction_prompt}"
                else:
                    enhanced_doc = f"SECURITY GUIDELINES:\n{candidate.security_guidelines}\n\nINSTRUCTION: {candidate.instruction_prompt}"
                
                SecurityEnhancedSignature.__doc__ = enhanced_doc
                
                # Update the module's signature
                module.signature = SecurityEnhancedSignature
        
        return configured_program
    
    def _create_optimized_program(self, 
                                student_program: dspy.Module,
                                best_candidate: GEPACandidate) -> dspy.Module:
        """Create optimized program from best candidate."""
        optimized_program = self._configure_program(student_program, best_candidate)
        
        # Store optimization metadata
        if not hasattr(optimized_program, '_gepa_metadata'):
            optimized_program._gepa_metadata = {}
        
        optimized_program._gepa_metadata.update({
            'best_candidate_id': best_candidate.candidate_id,
            'final_scores': best_candidate.scores,
            'instruction_prompt': best_candidate.instruction_prompt,
            'security_guidelines': best_candidate.security_guidelines,
            'performance_config': best_candidate.performance_config,
            'optimization_type': 'GEPA',
            'few_shot_examples_count': len(best_candidate.few_shot_examples)
        })
        
        # Apply few-shot examples if the program supports it
        if hasattr(optimized_program, 'set_examples') and best_candidate.few_shot_examples:
            optimized_program.set_examples(best_candidate.few_shot_examples)
        
        return optimized_program


# Integration with existing BanditTeleprompter
class GEPATeleprompter:
    """GEPA-based teleprompter for security optimization."""
    
    def __init__(self, 
                 metric,
                 task_lm: Optional[dspy.LM] = None,
                 reflection_lm: Optional[dspy.LM] = None,
                 max_iterations: int = 8,
                 population_size: int = 6):
        """
        Initialize GEPA teleprompter.
        
        Args:
            metric: Security evaluation metric
            task_lm: LM being optimized
            reflection_lm: Stronger LM for reflection
            max_iterations: Number of GEPA iterations
            population_size: Population size for evolution
        """
        self.metric = metric
        self.optimizer = SecurityGEPAOptimizer(
            task_lm=task_lm,
            reflection_lm=reflection_lm,
            max_iterations=max_iterations,
            population_size=population_size
        )
    
    def compile(self, student, *, trainset) -> dspy.Module:
        """Compile student program using GEPA optimization."""
        print("Starting GEPA optimization for security-aware code generation...")
        
        optimized_program, history = self.optimizer.optimize(
            student_program=student,
            trainset=trainset,
            security_metric=self.metric
        )
        
        print(f"GEPA optimization completed.")
        print(f"Final Pareto front size: {len(self.optimizer.pareto_selector.pareto_front)}")
        
        return optimized_program